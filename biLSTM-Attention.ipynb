{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "from keras.activations import softmax\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m is no. of training examples, each example has a sequence of Tx inputs\n",
    "Tx = 10\n",
    "Ty = 10\n",
    "frame_vals_len = 1805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax,name='attention_weights')\n",
    "dotor = Dot(axes = 1)\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "concatenator2 = Concatenate(axis=0)\n",
    "densor = Dense(1, activation = \"relu\")\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor(concat)\n",
    "    alphas = activator(e)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64\n",
    "n_s = 128\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(frame_vals_len, activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(Tx, Ty, n_a, n_s, frame_vals_len):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, frame_vals_len))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        out = output_layer(s)\n",
    "        #out = tf.reshape(out,(1,1805))\n",
    "        #print(\"out shape\",out.shape)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    outputs2 = outputs[0]\n",
    "    for softmax in range(1,10):\n",
    "        outputs2 = concatenator([outputs2,outputs[softmax]])\n",
    "\n",
    "    print(outputs2.shape)\n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs2)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_H = 19\n",
    "GRID_W = 19\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-92aeaf71e06e>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-92aeaf71e06e>\"\u001b[0;36m, line \u001b[0;32m72\u001b[0m\n\u001b[0;31m    true_maxes   = true_xy + true_wnot outputs:h_half\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 1, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., 1:3]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 3:5])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 0])\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 1:3] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 3:5] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 0], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalnp_arr_gt.shapeize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wnot outputs:h_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    np_arr_gt.shape\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "          \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    \"\"\"\n",
    "    Debugging code\n",
    "    \"\"\"    \n",
    "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "    total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "        \n",
    "    pick = []\n",
    "\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding boxes \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # finding the largest (x, y) coordinates for the start of the bounding box and the smallest (x, y) coordinates for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        \n",
    "        #width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        \n",
    "        #ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    return pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_conf_layer(x):\n",
    "    return np.delete(x,0,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: Array of shape(?,10,19,19,5) containing ground truth values for each sequence\n",
    "    y_pred: Array of shape(?,10,19,19,5) containing predicted values from final softmax layer for each sequence\n",
    "    \"\"\"\n",
    "    y_shape0 = K.shape(y_pred)[0]\n",
    "    y_pred = tf.reshape(y_pred,(K.shape(y_pred)[0],10,19,19,5))\n",
    "    y_true = tf.reshape(y_pred,(y_shape0,10,19,19,5))\n",
    "    #print(y_pred.get_shape().as_list()[1:5])\n",
    "    lambda_coord = 5\n",
    "    lambda_noobj = 0.5\n",
    "    #suppression of extremely less chance boxes\n",
    "    threshold = 0.5\n",
    "    int_mask = threshold*np.ones(y_pred.get_shape().as_list()[1:5])\n",
    "    #int_mask = threshold*np.ones(y_pred.get_shape().as_list(),tf.float32)\n",
    "    int_mask[...,1:5] = np.zeros((y_pred.get_shape().as_list()[1:5])[:3]+[4])\n",
    "    #int_mask[...,1:5] = tf.zeros((y_pred.get_shape().as_list(),tf.float32)[1:4]+[4])\n",
    "    int_mask = tf.convert_to_tensor(int_mask,dtype = tf.float32)\n",
    "    caster = tf.cast((y_pred-int_mask)>0,dtype = tf.float32)\n",
    "    mul_mask = np.ones(y_pred.get_shape().as_list()[1:5])\n",
    "    #mul_mask = tf.ones(y_pred.get_shape().as_list(),tf.float32)\n",
    "    mul_mask[...,1:5] = np.zeros((y_pred.get_shape().as_list()[1:5])[:3]+[4])\n",
    "    mul_mask = tf.convert_to_tensor(mul_mask,dtype = tf.float32)\n",
    "    caster = caster*mul_mask\n",
    "    caster = 0.5*caster\n",
    "    y_pred = tf.nn.relu(y_pred - int_mask)\n",
    "    y_pred = y_pred + caster\n",
    "    y_pred_new = np.zeros(y_pred.get_shape().as_list()[1:5])\n",
    "    y_pred_new[...,1:5] = np.ones((y_pred.get_shape().as_list()[1:5])[:3]+[4])\n",
    "    #non max suppression\n",
    "    \n",
    "    #selecting boxes and formatting for passing into nms\n",
    "    for i in range(Tx):\n",
    "        index_mask = np.zeros(y_pred.shape[2:])\n",
    "        index_mask[...,0] = np.reshape(np.arange(19*19)+1,(19,19))\n",
    "        boxes_selector = tf.where(y_pred[y_shape0,i]>0,tf.convert_to_tensor(index_mask),tf.convert_to_tensor(np.zeros(y_pred.shape[2:])))\n",
    "        box_locations = tf.contrib.layers.dense_to_sparse(boxes_selector).values\n",
    "        boxes_dims = []\n",
    "        coordinates_init = []\n",
    "        scores = []\n",
    "        for j in range(19*19):\n",
    "            try:\n",
    "                midpoint_index = box_locations[j]\n",
    "            except IndexError:\n",
    "                break\n",
    "            coordinate_y = tf.cast(tf.floor((midpoint_index-1)/19),tf.float32)\n",
    "            coordinate_y_int = tf.cast(coordinate_y,tf.int32)\n",
    "            coordinate_x = tf.cast((midpoint_index-1)%19,tf.float32)\n",
    "            coordinate_x_int = tf.cast((midpoint_index-1)%19,tf.int32)\n",
    "            score = y_pred[y_shape0,i,coordinate_x_int,coordinate_y_int,0]\n",
    "            xyhw = [(1/19)*(coordinate_x+y_pred[y_shape0,i,coordinate_x_int,coordinate_y_int,1]), (1/19)*(coordinate_y+y_pred[y_shape0,i,coordinate_x_int,coordinate_y_int,2]),(1/19)*(y_pred[y_shape0,i,coordinate_x_int,coordinate_y_int,3]),(1/19)*(y_pred[y_shape0,i,coordinate_x_int,coordinate_y_int,4])]\n",
    "            yx2 = [xyhw[1]-(xyhw[2]/2),xyhw[0]-(xyhw[3]/2),xyhw[1]+(xyhw[3]/2),xyhw[0]+(xyhw[3]/2)]\n",
    "            boxes_dims.append(yx2)\n",
    "            coordinates_init.append(midpoint_index)\n",
    "            scores.append(score)\n",
    "        selected_indices = tf.image.non_max_suppression(boxes=boxes_dims,scores = scores,max_output_size=tf.constant(2),iou_threshold=threshold)\n",
    "        coordinates_init = tf.convert_to_tensor(coordinates_init)\n",
    "        index_arr = np.reshape(np.arange(19*19),(19,19))\n",
    "        \n",
    "        for k in range(19*19):\n",
    "            try:\n",
    "                index = selected_indices[k]\n",
    "            except IndexError:\n",
    "                break\n",
    "            mid = coordinates_init[index]\n",
    "            #new_x = tf.cast(coords[0],tf.int32)\n",
    "            #new_y = tf.cast(coords[1],tf.int32)\n",
    "            \n",
    "            y_pred_new = y_pred_new + tf.where(index_mask == mid,mul_mask,np.zeros(y_pred.get_shape().as_list()[1:5])) \n",
    "            #y_pred_new[i,k,new_x,new_y,0] = 1\n",
    "            \n",
    "    y_pred = y_pred*y_pred_new        \n",
    "    \n",
    "    #calculating loss using yolo loss function\n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., 1:3])\n",
    "    pred_box_hw = tf.exp(y_pred[..., 3:5])\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 0])\n",
    "    \n",
    "    true_box_xy = y_true[...,1:3]\n",
    "    true_box_hw = y_true[...,3:5]\n",
    "    true_box_conf = y_true[...,0]\n",
    "    \n",
    "    \n",
    "    pred_box_x = tf.sigmoid(y_pred[..., 1])\n",
    "    pred_box_y = tf.sigmoid(y_pred[..., 2])\n",
    "    pred_box_h = tf.exp(y_pred[..., 3])\n",
    "    pred_box_w = tf.exp(y_pred[..., 4])\n",
    "    #pred_box_conf = tf.sigmoid(y_pred[..., 0])\n",
    "    \n",
    "    true_box_x = y_true[...,1]\n",
    "    true_box_y = y_true[...,2]\n",
    "    true_box_h = y_true[...,3]\n",
    "    true_box_w = y_true[...,4]\n",
    "    #true_box_conf = y_true[...,0]\n",
    "    \n",
    "    loss_xy = lambda_coord*tf.reduce_sum(true_box_conf*(tf.square(true_box_x-pred_box_x)+tf.square(true_box_y-pred_box_y)))\n",
    "    loss_wh = lambda_coord*tf.reduce_sum(true_box_conf*(tf.square(tf.sqrt(true_box_h)-tf.sqrt(pred_box_h))+tf.square(tf.sqrt(true_box_w)-tf.sqrt(pred_box_w))))\n",
    "    loss_conf = tf.reduce_sum(true_box_conf*tf.square(true_box_conf - pred_box_conf)) + lambda_noobj*tf.reduce_sum(tf.abs(true_box_conf-tf.ones(true_box_conf.get_shape().as_list()[1:5]))*tf.square(true_box_conf - pred_box_conf))\n",
    "    loss = loss_xy + loss_wh + loss_conf\n",
    "    #debugging\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" \n",
    "    for i in range(Tx):\n",
    "        index_of_boxes = []\n",
    "        boxes_dims =[]\n",
    "        for j in range(GRID_H):\n",
    "            for k in range(GRID_W):\n",
    "                if y_pred[K.shape(y_pred)[0],i,j,k,0]>0 is not None:\n",
    "                    index_of_boxes.append([i,j,k])\n",
    "                    xyhw = [(1/19)*(j+y_pred[i,j,k,1]), (1/19)*(k+y_pred[i,j,k,2]),(1/19)*(y_pred[i,j,k,3]),(1/19)*(y_pred[i,j,k,4])]\n",
    "                    xy2 = [xywh[0]-(xywh[3]/2),xywh[1]-(xywh[2]/2),xywh[0]+(xywh[3]/2),xywh[1]+(xywh[3]/2)]\n",
    "                    boxes_dims.append(xy2)\n",
    "        picked_boxes_indices = non_max_suppression_fast(boxes_dims, threshold)\n",
    "        for index in picked_boxes_indices:\n",
    "            picked_box = boxes_dims[index]\n",
    "            new_xyhw = [(picked_box[2] - picked_box[0])/2,(picked_box[3] - picked_box[1])/2,picked_box[3] - picked_box[1], picked_box[2] - picked_box[0]]\n",
    "            y_pred_new[i,int(new_xywh[0]/(1/19)),int(new_xywh[1]/(1/19)),1] = new_xyhw[0]/(1/19) - int(new_xyhw[0]/(1/19))\n",
    "            y_pred_new[i,int(new_xywh[0]/(1/19)),int(new_xywh[1]/(1/19)),2] = new_xyhw[1]/(1/19) - int(new_xyhw[1]/(1/19))\n",
    "            y_pred_new[i,int(new_xywh[0]/(1/19)),int(new_xywh[1]/(1/19)),3] = new_xyhw[2]/(1/19)\n",
    "            y_pred_new[i,int(new_xywh[0]/(1/19)),int(new_xywh[1]/(1/19)),4] = new_xyhw[3]/(1/19)\n",
    "        y_pred = tf.convert_to_tensor(y_pred_new)\n",
    "    \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.5,   2.5,   4.5,   6.5,   8.5],\n",
       "        [ 10.5,  12.5,  14.5,  16.5,  18.5],\n",
       "        [ 20.5,  22.5,  24.5,  26.5,  28.5],\n",
       "        [ 30.5,  32.5,  34.5,  36.5,  38.5],\n",
       "        [ 40.5,  42.5,  44.5,  46.5,  48.5]],\n",
       "\n",
       "       [[ 50.5,  52.5,  54.5,  56.5,  58.5],\n",
       "        [ 60.5,  62.5,  64.5,  66.5,  68.5],\n",
       "        [ 70.5,  72.5,  74.5,  76.5,  78.5],\n",
       "        [ 80.5,  82.5,  84.5,  86.5,  88.5],\n",
       "        [ 90.5,  92.5,  94.5,  96.5,  98.5]],\n",
       "\n",
       "       [[100.5, 102.5, 104.5, 106.5, 108.5],\n",
       "        [110.5, 112.5, 114.5, 116.5, 118.5],\n",
       "        [120.5, 122.5, 124.5, 126.5, 128.5],\n",
       "        [130.5, 132.5, 134.5, 136.5, 138.5],\n",
       "        [140.5, 142.5, 144.5, 146.5, 148.5]],\n",
       "\n",
       "       [[150.5, 152.5, 154.5, 156.5, 158.5],\n",
       "        [160.5, 162.5, 164.5, 166.5, 168.5],\n",
       "        [170.5, 172.5, 174.5, 176.5, 178.5],\n",
       "        [180.5, 182.5, 184.5, 186.5, 188.5],\n",
       "        [190.5, 192.5, 194.5, 196.5, 198.5]],\n",
       "\n",
       "       [[200.5, 202.5, 204.5, 206.5, 208.5],\n",
       "        [210.5, 212.5, 214.5, 216.5, 218.5],\n",
       "        [220.5, 222.5, 224.5, 226.5, 228.5],\n",
       "        [230.5, 232.5, 234.5, 236.5, 238.5],\n",
       "        [240.5, 242.5, 244.5, 246.5, 248.5]],\n",
       "\n",
       "       [[250.5, 252.5, 254.5, 256.5, 258.5],\n",
       "        [260.5, 262.5, 264.5, 266.5, 268.5],\n",
       "        [270.5, 272.5, 274.5, 276.5, 278.5],\n",
       "        [280.5, 282.5, 284.5, 286.5, 288.5],\n",
       "        [290.5, 292.5, 294.5, 296.5, 298.5]],\n",
       "\n",
       "       [[300.5, 302.5, 304.5, 306.5, 308.5],\n",
       "        [310.5, 312.5, 314.5, 316.5, 318.5],\n",
       "        [320.5, 322.5, 324.5, 326.5, 328.5],\n",
       "        [330.5, 332.5, 334.5, 336.5, 338.5],\n",
       "        [340.5, 342.5, 344.5, 346.5, 348.5]],\n",
       "\n",
       "       [[350.5, 352.5, 354.5, 356.5, 358.5],\n",
       "        [360.5, 362.5, 364.5, 366.5, 368.5],\n",
       "        [370.5, 372.5, 374.5, 376.5, 378.5],\n",
       "        [380.5, 382.5, 384.5, 386.5, 388.5],\n",
       "        [390.5, 392.5, 394.5, 396.5, 398.5]],\n",
       "\n",
       "       [[400.5, 402.5, 404.5, 406.5, 408.5],\n",
       "        [410.5, 412.5, 414.5, 416.5, 418.5],\n",
       "        [420.5, 422.5, 424.5, 426.5, 428.5],\n",
       "        [430.5, 432.5, 434.5, 436.5, 438.5],\n",
       "        [440.5, 442.5, 444.5, 446.5, 448.5]],\n",
       "\n",
       "       [[450.5, 452.5, 454.5, 456.5, 458.5],\n",
       "        [460.5, 462.5, 464.5, 466.5, 468.5],\n",
       "        [470.5, 472.5, 474.5, 476.5, 478.5],\n",
       "        [480.5, 482.5, 484.5, 486.5, 488.5],\n",
       "        [490.5, 492.5, 494.5, 496.5, 498.5]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.reshape(0.5*np.arange(1000),(10,5,5,4))\n",
    "mask = np.ones((10,5,5,4))\n",
    "#a = tf.convert_to_tensor(a,dtype = tf.float32)\n",
    "mask[...,1:4] = np.zeros((10,5,5,3))\n",
    "mask = mask/2\n",
    "mask = tf.convert_to_tensor(mask,dtype = tf.float32)\n",
    "a = tf.convert_to_tensor(a,dtype = tf.float32)\n",
    "#a = tf.cast(a >= 5.5,dtype = np.int32)\n",
    "np_a = tf.Session().run(a)\n",
    "b = np.zeros(a.shape)\n",
    "b[...,0] = np.reshape(np.arange(250),(10,5,5))\n",
    "c = tf.where(a>5,tf.convert_to_tensor(b),tf.convert_to_tensor(np.zeros(a.shape)))\n",
    "#c_sparse = tf.contrib.layers.dense_to_sparse(c).values\n",
    "d = tf.zeros([1,1])\n",
    "#print(np_a[1,1,2,1])\n",
    "x_coord = tf.constant(1)\n",
    "y_coord = tf.constant(2)\n",
    "var = tf.Variable(tf.ones((10,5,5,4),tf.float32))\n",
    "np_a[...,1]\n",
    "\n",
    "#print(x_coord)\n",
    "#print(np_a[1,x_coord,y_coord,1])\n",
    "#tf.Session().run(c_sparse)\n",
    "#tf.where(a>5.5,tf.convert_to_tensor(b),tf.convert_to_tensor(np.zeros(a.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 18050)\n"
     ]
    }
   ],
   "source": [
    "model = model_fn(Tx, Ty, n_a, n_s, 1805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 10, 1805)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 128)      957440      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 10, 128)      0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     multiple             0           bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[1][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[2][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[3][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[4][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[5][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[6][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[7][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[8][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 repeat_vector_2[9][0]            \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 concatenate_2[10][0]             \n",
      "                                                                 dense_3[2][0]                    \n",
      "                                                                 concatenate_2[11][0]             \n",
      "                                                                 dense_3[3][0]                    \n",
      "                                                                 concatenate_2[12][0]             \n",
      "                                                                 dense_3[4][0]                    \n",
      "                                                                 concatenate_2[13][0]             \n",
      "                                                                 dense_3[5][0]                    \n",
      "                                                                 concatenate_2[14][0]             \n",
      "                                                                 dense_3[6][0]                    \n",
      "                                                                 concatenate_2[15][0]             \n",
      "                                                                 dense_3[7][0]                    \n",
      "                                                                 concatenate_2[16][0]             \n",
      "                                                                 dense_3[8][0]                    \n",
      "                                                                 concatenate_2[17][0]             \n",
      "                                                                 dense_3[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10, 1)        257         concatenate_2[0][0]              \n",
      "                                                                 concatenate_2[1][0]              \n",
      "                                                                 concatenate_2[2][0]              \n",
      "                                                                 concatenate_2[3][0]              \n",
      "                                                                 concatenate_2[4][0]              \n",
      "                                                                 concatenate_2[5][0]              \n",
      "                                                                 concatenate_2[6][0]              \n",
      "                                                                 concatenate_2[7][0]              \n",
      "                                                                 concatenate_2[8][0]              \n",
      "                                                                 concatenate_2[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 10, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 131584      dot_2[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_2[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_2[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_2[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_2[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_2[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_2[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_2[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_2[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_2[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1805)         232845      lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,322,126\n",
      "Trainable params: 1,322,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-42d5ddb3a01c>:101: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = model.compile(optimizer=Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01),\n",
    "                    loss=my_loss)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
