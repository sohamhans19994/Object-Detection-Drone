{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "from preprocessing import  parse_annotation,BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = '/home/soham/darknet/yolov3.weights'                      \n",
    "train_image_folder = '/home/andy/data/coco/train2014/'\n",
    "train_annot_folder = '/home/andy/data/coco/train2014ann/'\n",
    "valid_image_folder = '/home/andy/data/coco/val2014/'\n",
    "valid_annot_folder = '/home/andy/data/coco/val2014ann/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tiny_yolo_model(input_shape,num_classes):\n",
    "    input_image = Input(input_shape)\n",
    "    #layer1\n",
    "    x = Conv2D(16, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #layer2\n",
    "    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_2')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #layer3\n",
    "    x = Conv2D(16, (1,1), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_3')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer4\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_4')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer5\n",
    "    x = Conv2D(16, (1,1), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_5')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer6\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #layer7\n",
    "    x = Conv2D(32, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_7')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer8\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_8')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer9\n",
    "    x = Conv2D(32, (1,1), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_9')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer10\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_10')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #layer11\n",
    "    x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_11')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer12\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_12')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer13\n",
    "    x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_13')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer14\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_14')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #layer15\n",
    "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_15')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    #softmax layer\n",
    "    x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_16')(x)\n",
    "    #output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "    model = Model([input_image],x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 416, 416, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 416, 416, 16)      432       \n",
      "_________________________________________________________________\n",
      "norm_1 (BatchNormalization)  (None, 416, 416, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 416, 416, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 208, 208, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 208, 208, 32)      4608      \n",
      "_________________________________________________________________\n",
      "norm_2 (BatchNormalization)  (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 104, 104, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 104, 104, 16)      512       \n",
      "_________________________________________________________________\n",
      "norm_3 (BatchNormalization)  (None, 104, 104, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 104, 104, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 104, 104, 128)     18432     \n",
      "_________________________________________________________________\n",
      "norm_4 (BatchNormalization)  (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 104, 104, 16)      2048      \n",
      "_________________________________________________________________\n",
      "norm_5 (BatchNormalization)  (None, 104, 104, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 104, 104, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 104, 104, 128)     18432     \n",
      "_________________________________________________________________\n",
      "norm_6 (BatchNormalization)  (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 52, 52, 32)        4096      \n",
      "_________________________________________________________________\n",
      "norm_7 (BatchNormalization)  (None, 52, 52, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 52, 52, 256)       73728     \n",
      "_________________________________________________________________\n",
      "norm_8 (BatchNormalization)  (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_9 (Conv2D)              (None, 52, 52, 32)        8192      \n",
      "_________________________________________________________________\n",
      "norm_9 (BatchNormalization)  (None, 52, 52, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_10 (Conv2D)             (None, 52, 52, 256)       73728     \n",
      "_________________________________________________________________\n",
      "norm_10 (BatchNormalization) (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_11 (Conv2D)             (None, 26, 26, 64)        16384     \n",
      "_________________________________________________________________\n",
      "norm_11 (BatchNormalization) (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_12 (Conv2D)             (None, 26, 26, 512)       294912    \n",
      "_________________________________________________________________\n",
      "norm_12 (BatchNormalization) (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_13 (Conv2D)             (None, 26, 26, 64)        32768     \n",
      "_________________________________________________________________\n",
      "norm_13 (BatchNormalization) (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_14 (Conv2D)             (None, 26, 26, 512)       294912    \n",
      "_________________________________________________________________\n",
      "norm_14 (BatchNormalization) (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_15 (Conv2D)             (None, 26, 26, 128)       65536     \n",
      "_________________________________________________________________\n",
      "norm_15 (BatchNormalization) (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_16 (Conv2D)             (None, 26, 26, 425)       54825     \n",
      "=================================================================\n",
      "Total params: 972,313\n",
      "Trainable params: 967,929\n",
      "Non-trainable params: 4,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = my_tiny_yolo_model([IMAGE_H,IMAGE_W,3],CLASS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader = WeightReader(wt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "nb_conv = 16\n",
    "\n",
    "for i in range(1, nb_conv+1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        beta  = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean  = weight_reader.read_bytes(size)\n",
    "        var   = weight_reader.read_bytes(size)\n",
    "\n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "        \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
