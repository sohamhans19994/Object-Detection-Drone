{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Keras version 2.2.4 detected. Last version known to be fully compatible of Keras is 2.1.6 .\n",
      "WARNING:root:TensorFlow version 1.12.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import groupby\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.models import Model\n",
    "from coremltools.converters.keras import convert\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = (240, 240)\n",
    "img_folder = Path(\"/home/soham/AeroMIT/dataset_exploiting/kmeans_version/\").expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Network for Feature Extraction\n",
    "We load the model which has been trained on ImageNet. We specify `include_top=False`.  This ensures that we don't load the final layers specific to the classes the model was originall trained to predict. For more information, see the [Keras documentation](https://keras.io/applications/#resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = VGG16(input_shape=(IMG_HEIGHT,IMG_WIDTH,3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(encoder_model.output.shape.as_list()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = []\n",
    "for filename in os.listdir(img_folder):\n",
    "    image_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images:  7908\n",
      "train images 71165\n"
     ]
    }
   ],
   "source": [
    "train_filenames, test_filenames = train_test_split(image_filenames, test_size=0.1)\n",
    "print(\"test images: \", len(test_filenames))\n",
    "print(\"train images\", len(train_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features for all images in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca3d456574d4c5981fe8a523144e46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4448), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir(img_folder)\n",
    "filename_order = []\n",
    "def load_encode_images(encoder, filenames):\n",
    "    batch_size = 16\n",
    "    encoded_dim = np.prod(encoder.output.shape[1:]).value\n",
    "    file_count = len(filenames)\n",
    "    encoded = np.zeros((file_count, encoded_dim))\n",
    "    for start_index in tqdm(list(range(0, file_count, batch_size))):\n",
    "        end_index = min(start_index + batch_size, file_count)\n",
    "        batch_filenames = filenames[start_index:end_index]\n",
    "\n",
    "        batch_images = load_images(filename_order,batch_filenames)\n",
    "        batch_encoded = encoder.predict(batch_images)\n",
    "        batch_encoded_flat = batch_encoded.reshape(len(batch_images), -1)\n",
    "        encoded[start_index:end_index, :] = batch_encoded_flat\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def load_images(filename_order,filenames):\n",
    "    images = np.zeros((len(filenames), IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = image.load_img(filename, target_size=(IMG_HEIGHT,IMG_WIDTH))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        images[i, :, :, :] = img_array\n",
    "        filename_order.append([i,filename])\n",
    "    return images\n",
    "\n",
    "encoded_imgs = load_encode_images(encoder_model, train_filenames).T\n",
    "print(filename_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71164, 25088)\n"
     ]
    }
   ],
   "source": [
    "encoded_imgs = encoded_imgs.T\n",
    "print(encoded_imgs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buiding the Kmeans using minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "k = 20 # The number of clusters\n",
    "num_features = 25088\n",
    "#X = tf.placeholder(tf.float32, shape=[num_features,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=k, random_state=0, batch_size=200, max_iter=100000).fit(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 25088)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(kmeans.cluster_centers_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/soham/AeroMIT/rnn_yolo_model/keras-knn/labels_20_v2clusters.csv\",labels,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"image_filename_order.txt\",'w') as f:\n",
    "    for file in filename_order:\n",
    "        f.write(str(file) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.839708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.376889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  71164.000000\n",
       "mean       5.839708\n",
       "std        2.376889\n",
       "min        0.000000\n",
       "25%        7.000000\n",
       "50%        7.000000\n",
       "75%        7.000000\n",
       "max        9.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.DataFrame(labels)\n",
    "labels_df['filenames'] = [filename[1] for file in filename_order]\n",
    "labels_df.to_csv('/home/soham/AeroMIT/rnn_yolo_model/keras-knn/labels_20_filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(img_folder)\n",
    "prediction_filename_order = []\n",
    "def load_predict_encode_images(encoder, filenames):\n",
    "    batch_size = 16\n",
    "    encoded_dim = np.prod(encoder.output.shape[1:]).value\n",
    "    file_count = len(filenames)\n",
    "    encoded = np.zeros((file_count, encoded_dim))\n",
    "    for start_index in tqdm(list(range(0, file_count, batch_size))):\n",
    "        end_index = min(start_index + batch_size, file_count)\n",
    "        batch_filenames = filenames[start_index:end_index]\n",
    "\n",
    "        batch_images = load_predict_images(filename_order,batch_filenames)\n",
    "        batch_encoded = encoder.predict(batch_images)\n",
    "        batch_encoded_flat = batch_encoded.reshape(len(batch_images), -1)\n",
    "        encoded[start_index:end_index, :] = batch_encoded_flat\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def load_predict_images(filename_order,filenames):\n",
    "    images = np.zeros((len(filenames), IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = image.load_img(filename, target_size=(IMG_HEIGHT,IMG_WIDTH))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        images[i, :, :, :] = img_array\n",
    "        prediction_filename_order.append([i,filename])\n",
    "    return images\n",
    "\n",
    "encoded_predict_imgs = load_predict_encode_images(encoder_model, test_filenames)\n",
    "print(predict_filename_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>(a, b)</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  (a, b)  a\n",
       "0  1  2  [5, 6]  5\n",
       "1  3  4  [7, 8]  7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_labels = kmeans.predict(encoded_predict_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels_df = pd.DataFrame(labels)\n",
    "predict_labels_df['filenames'] = [filename[1] for file in predict_filename_order]\n",
    "predict_labels_df.to_csv('/home/soham/AeroMIT/rnn_yolo_model/keras-knn/predict_labels_20_filenames.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
